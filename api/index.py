import os
import re
import base64
import json
from http.server import BaseHTTPRequestHandler
from io import BytesIO

# --- Dependencies ---
import fitz  # PyMuPDF
from docx import Document
from langchain_core.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_google_genai import ChatGoogleGenerativeAI

# ==============================================================================
# CONSOLIDATED LOGIC
# ==============================================================================

# --- Initialize LLM ---
llm = None
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if GOOGLE_API_KEY:
    try:
        llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash-latest", google_api_key=GOOGLE_API_KEY)
    except Exception as e:
        print(f"[api] Failed to initialize LLM: {e}")

# --- Combined LLM analysis function ---
def get_llm_analysis(resume_text: str, jd_text: str) -> dict:
    if not llm:
        return {"score": 0, "suggestions": "LLM not available. Check API key."}
    try:
        # UPDATED: More robust prompt to enforce JSON output
        prompt = PromptTemplate.from_template(
            """Your task is to analyze a resume against a job description.
You MUST respond ONLY with a single, valid JSON object. Do not include any text or formatting before or after the JSON object.
The JSON object must contain two keys: "score" and "suggestions".
- "score": An integer between 0 and 100 for match quality.
- "suggestions": A brief string of actionable resume improvement advice, using newline characters (\\n) for bullet points.

Example of a perfect response:
{{"score": 75, "suggestions": "- Highlight cloud experience like AWS.\\n- Quantify achievements with metrics."}}

JD: {jd}
Resume: {resume}
JSON Response:
"""
        )
        chain = LLMChain(llm=llm, prompt=prompt)
        response_text = chain.invoke({"resume": resume_text, "jd": jd_text}).get("text", "{}")
        
        # More resilient JSON parsing
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if not json_match:
            print(f"[api] AI response did not contain valid JSON: {response_text}")
            return {"score": 0, "suggestions": "AI response was not in the correct format."}

        clean_json_str = json_match.group(0)
        parsed_json = json.loads(clean_json_str)

        score_val = parsed_json.get("score", 0)
        suggestions_val = parsed_json.get("suggestions", "No suggestions were generated by the AI.")
        
        normalized_score = (int(score_val) / 100) * 50
        
        return {"score": max(0, min(normalized_score, 50)), "suggestions": suggestions_val}
    except json.JSONDecodeError as json_err:
        print(f"[api] JSON Parsing Error: {json_err}. AI Response was: {response_text}")
        return {"score": 0, "suggestions": "Failed to parse AI feedback. The format was invalid."}
    except Exception as e:
        print(f"[api] Critical error in get_llm_analysis: {e}")
        return {"score": 0, "suggestions": "An unexpected error occurred during AI analysis."}

# --- Text extraction and keyword matching logic ---
STOP_WORDS = {'and', 'the', 'of', 'in', 'to', 'a', 'with', 'for', 'on', 'is', 'are', 'an'}
KNOWN_SKILLS = {
    'python', 'java', 'javascript', 'typescript', 'c#', 'c++', 'php', 'ruby', 'go', 'swift', 'kotlin', 'sql', 'nosql',
    'html', 'css', 'react', 'angular', 'vue', 'nodejs', 'express', 'django', 'flask', 'fastapi',
    'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'terraform', 'ansible', 'jenkins', 'ci/cd',
    'machine learning', 'deep learning', 'tensorflow', 'pytorch', 'scikit-learn', 'pandas', 'numpy', 'matplotlib',
    'data analysis', 'data visualization', 'tableau', 'power bi', 'mysql', 'postgresql', 'mongodb', 'redis', 
    'git', 'linux', 'rest api', 'graphql', 'agile', 'scrum', 'communication', 'teamwork', 'problem solving'
}

def extract_text_from_pdf(file_bytes: bytes) -> str:
    try:
        with fitz.open(stream=file_bytes, filetype="pdf") as doc:
            return "".join(page.get_text() for page in doc)
    except Exception as e:
        print(f"[api] Error reading PDF: {e}")
        return ""

def extract_text_from_docx(file_bytes: bytes) -> str:
    try:
        return "\n".join(para.text for para in Document(BytesIO(file_bytes)).paragraphs)
    except Exception as e:
        print(f"[api] Error reading DOCX: {e}")
        return ""

def get_hard_match_score(resume_text: str, jd_text: str):
    jd_skills = {skill for skill in KNOWN_SKILLS if skill in jd_text.lower()}
    if not jd_skills:
        return 0.0, [], []
    resume_skills_present = {skill for skill in KNOWN_SKILLS if skill in resume_text.lower()}
    matched = jd_skills.intersection(resume_skills_present)
    missing = jd_skills.difference(resume_skills_present)
    score = (len(matched) / len(jd_skills)) * 50 if jd_skills else 0
    return score, sorted(list(matched)), sorted(list(missing))

# ==============================================================================
# MAIN HANDLER FOR VERCEL
# ==============================================================================
class handler(BaseHTTPRequestHandler):
    def do_POST(self):
        try:
            content_length = int(self.headers['Content-Length'])
            post_data_bytes = self.rfile.read(content_length)
            body = json.loads(post_data_bytes.decode('utf-8'))
            
            job_description_data = body.get('job_description', '')
            resume_data = body.get('resume', None)

            if not job_description_data or not resume_data:
                self.send_response(400)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                self.wfile.write(json.dumps({"error": "Missing job description or resume"}).encode('utf-8'))
                return

            job_description_text = ""
            if isinstance(job_description_data, str) and job_description_data.startswith("data:"):
                header, jd_base64 = job_description_data.split(',', 1)
                jd_bytes = base64.b64decode(jd_base64)
                if 'pdf' in header.lower():
                    job_description_text = extract_text_from_pdf(jd_bytes)
                elif 'wordprocessingml' in header.lower():
                    job_description_text = extract_text_from_docx(jd_bytes)
            else:
                job_description_text = job_description_data

            file_name, content = resume_data.get('fileName'), resume_data.get('content')
            header, base64_content = content.split(',', 1)
            file_bytes = base64.b64decode(base64_content)
            
            resume_text = ""
            if file_name.lower().endswith('.pdf'): resume_text = extract_text_from_pdf(file_bytes)
            elif file_name.lower().endswith('.docx'): resume_text = extract_text_from_docx(file_bytes)

            if not resume_text:
                raise ValueError("Could not read resume text.")

            email_match = re.search(r'\b[A-Za-z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}\b', resume_text, re.IGNORECASE)
            candidate_email = email_match.group(0) if email_match else "N/A"

            hard_score, matched_skills, missing_skills = get_hard_match_score(resume_text, job_description_text)
            llm_results = get_llm_analysis(resume_text, job_description_text)
            
            total_score = round(hard_score + llm_results["score"])
            verdict = "High" if total_score >= 80 else "Medium" if total_score >= 50 else "Low"
            
            result = {
                "resumeName": file_name,
                "candidateEmail": candidate_email,
                "score": total_score,
                "verdict": verdict,
                "missingSkills": missing_skills,
                "suggestions": llm_results["suggestions"]
            }
            
            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            self.wfile.write(json.dumps(result).encode('utf-8'))

        except Exception as e:
            self.send_response(500)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            self.wfile.write(json.dumps({"error": f"An internal server error occurred: {str(e)}"}).encode('utf-8'))

